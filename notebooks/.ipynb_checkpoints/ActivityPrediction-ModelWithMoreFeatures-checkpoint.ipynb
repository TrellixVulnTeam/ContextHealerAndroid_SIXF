{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature engineering \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Charts\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Static params\n",
    "DATA_FOLDER = 'Data/'\n",
    "DATA_FILE = 'raw_data_fixed.txt'\n",
    "\n",
    "\n",
    "class ActitrackerLR:\n",
    "    ''' Logistic Regression models\n",
    "        one for each class\n",
    "    '''\n",
    "    @staticmethod\n",
    "    def train_models(X_train, Y_train, model_params):\n",
    "        ''' Train models iteratively \n",
    "            for each class\n",
    "        '''\n",
    "        models = [] \n",
    "        for i in xrange(Y_train.shape[1]):\n",
    "            model = LogisticRegression(**model_params)\n",
    "            y = Y_train[:,i]\n",
    "            model.fit(X_train, y)\n",
    "            models.append(model)\n",
    "        return models\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_predictions(X_test, models, num_classes=6):\n",
    "        ''' Make predictions \n",
    "            for each class \n",
    "        '''\n",
    "        predictions = np.zeros((X_test.shape[0], num_classes))\n",
    "        for i, model in enumerate(models):\n",
    "            p = model.predict_proba(X_test)\n",
    "            predictions[:,i] = p[:,1]\n",
    "        return predictions\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    global actitracker\n",
    "    actitracker = pd.read_csv(\n",
    "        DATA_FOLDER+DATA_FILE ,\n",
    "        sep=',' ,\n",
    "        lineterminator=';' ,\n",
    "        header=None ,\n",
    "    )\n",
    "    actitracker.columns = [\n",
    "        'user' ,\n",
    "        'activity' ,\n",
    "        'timestamp' ,\n",
    "        'x-accel' ,\n",
    "        'y-accel' ,\n",
    "        'z-accel' ,\n",
    "        'NA' ,\n",
    "    ]\n",
    "    del actitracker['NA']\n",
    "\n",
    "\n",
    "def create_sessions():\n",
    "    global actitracker\n",
    "    # re-calculate time in seconds\n",
    "    actitracker['time_seconds'] = actitracker['timestamp']*10e-9\n",
    "\n",
    "    # sort by user and time \n",
    "    actitracker = actitracker.sort_values(by=['user','time_seconds'])\n",
    "\n",
    "    # create sessions\n",
    "    session_length = 100\n",
    "    actitracker['seq'] = xrange(actitracker.shape[0])\n",
    "    actitracker['session'] = actitracker.\\\n",
    "                               groupby(['user','activity'])['seq'].\\\n",
    "                               apply(lambda x: x%session_length == 0).\\\n",
    "                               fillna(0).cumsum()\n",
    "\n",
    "\n",
    "def gather_target_vars():\n",
    "    global label_lookup\n",
    "    # get session_labels \n",
    "    ohe = OneHotEncoder(sparse=False); le = LabelEncoder()\n",
    "    labels = actitracker.groupby(['user','session'])['activity'].apply(lambda x: max(x))\n",
    "    le_labels = le.fit_transform(labels)\n",
    "    ohe_labels = ohe.fit_transform(le_labels.reshape(-1,1))\n",
    "    label_lookup = { k: v for k,v in set((i, v) for i,v in np.vstack((le_labels,labels)).T) }\n",
    "    \n",
    "    # create target variables\n",
    "    Y = pd.DataFrame(ohe_labels,index=labels.index)\n",
    "    return Y,labels\n",
    "\n",
    "\n",
    "get_label = np.vectorize(lambda x: label_lookup[x])\n",
    "\n",
    "\n",
    "def feature_engineering():\n",
    "    # group by user and session\n",
    "    accel_cols = ['x-accel','y-accel','z-accel']\n",
    "    g = actitracker.loc[:,accel_cols+['user','session']].groupby(['user','session'])\n",
    "    #print 'Feature engineering : {0}'.format(g[accel_cols[0]])\n",
    "\n",
    "    # IQR function\n",
    "    def iqr(x):\n",
    "        ''' calculate IQR from array\n",
    "        '''\n",
    "        q75, q25 = np.percentile(x, [75,25])\n",
    "        return q75-q25\n",
    "\n",
    "    # calculate model cols \n",
    "    means = g[accel_cols].apply(lambda x: np.mean(x))\n",
    "    sds = g[accel_cols].apply(lambda x: np.std(x))\n",
    "    median_1 = g[accel_cols[0]].apply(lambda x: np.median(x))\n",
    "    median_2 = g[accel_cols[1]].apply(lambda x: np.median(x))\n",
    "    median_3 = g[accel_cols[2]].apply(lambda x: np.median(x))\n",
    "    iqr_1 = g[accel_cols[0]].apply(lambda x: iqr(x))\n",
    "    iqr_2 = g[accel_cols[1]].apply(lambda x: iqr(x))\n",
    "    iqr_3 = g[accel_cols[2]].apply(lambda x: iqr(x))\n",
    "    mins = g[accel_cols].apply(lambda x: np.min(x))\n",
    "    maxs = g[accel_cols].apply(lambda x: np.max(x))\n",
    "    kurtosis_1 = g[accel_cols[0]].apply(lambda x: sp.stats.kurtosis(x))\n",
    "    kurtosis_2 = g[accel_cols[1]].apply(lambda x: sp.stats.kurtosis(x))\n",
    "    kurtosis_3 = g[accel_cols[2]].apply(lambda x: sp.stats.kurtosis(x))\n",
    "    skew_1 = g[accel_cols[0]].apply(lambda x: sp.stats.skew(x))\n",
    "    skew_2 = g[accel_cols[1]].apply(lambda x: sp.stats.skew(x))\n",
    "    skew_3 = g[accel_cols[2]].apply(lambda x: sp.stats.skew(x))\n",
    "    percentiles = []\n",
    "    for i in range(10,100,10):\n",
    "        for e in range(1,4):\n",
    "            percentiles.append(eval('g[accel_cols['+str(e-1)+']].apply(lambda x: sp.percentile(x,'+str(i)+'))'))\n",
    "\n",
    "    # concat columns\n",
    "    X = pd.concat([means,\n",
    "                    sds,\n",
    "                   median_1,\n",
    "                   median_2,\n",
    "                   median_3,\n",
    "                   iqr_1,\n",
    "                   iqr_2,\n",
    "                   iqr_3,\n",
    "                   mins,\n",
    "                   maxs,\n",
    "                   kurtosis_1,\n",
    "                   kurtosis_2,\n",
    "                   kurtosis_3,\n",
    "                   skew_1,\n",
    "                   skew_2,\n",
    "                   skew_3,\n",
    "                  ]+percentiles\n",
    "                  ,axis=1)\n",
    "\n",
    "    # Scale data\n",
    "    ss = StandardScaler()\n",
    "    X = ss.fit_transform(X)\n",
    "    return X, ss\n",
    "\n",
    "\n",
    "def lr_evaluate_params(c_values):\n",
    "    accuracies = []\n",
    "    log_losses = []\n",
    "    for c in c_values:\n",
    "        params = {'C':c,'max_iter':1000,'tol':1e-8}\n",
    "        models = lrmodel.train_models(X_train, Y_train, params)\n",
    "        predictions = lrmodel.make_predictions(X_test, models, 6)\n",
    "        accuracy = accuracy_score(np.argmax(Y_test, axis=1), np.argmax(predictions,axis=1))\n",
    "        ll = log_loss(Y_test, predictions)\n",
    "        accuracies.append(accuracy)\n",
    "        log_losses.append(ll)\n",
    "    evaluation = pd.DataFrame({'C':c_values,'accuracy':accuracies,'log_loss':log_losses})\n",
    "    print evaluation\n",
    "    return evaluation\n",
    "\n",
    "\n",
    "def lr_param_charts(c_values, accuracies, log_losses):\n",
    "    plt.figure(figsize=(14, 4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(np.log(c_values), accuracies, 'g')\n",
    "    plt.title(\"Change in Accuracy with Decreasing Regularization\")\n",
    "    plt.xlabel(\"Log of Inv. Regularization Strength (C)\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(np.log(c_values), log_losses, 'b')\n",
    "    plt.title(\"Change in Log-loss with Decreasing Regularization\")\n",
    "    plt.xlabel(\"Log of Inv. Regularization Strength (C)\")\n",
    "    plt.ylabel(\"Log-loss\")\n",
    "\n",
    "\n",
    "def print_accuracy(true_category, pred_category):\n",
    "    print 'Accuracy: {}'.format(accuracy_score(true_category, pred_category ))\n",
    "    print 'Log-loss: {}'.format(log_loss(Y_test, predictions))\n",
    "\n",
    "\n",
    "def analyze_errors(true_category, pred_category, get_label=get_label):\n",
    "    errors = pred_category != true_category\n",
    "    true_labels = get_label(true_category)\n",
    "    base = np.ones(true_labels.shape)\n",
    "    error_base = pd.DataFrame({'errors':errors,\n",
    "                      'labels':true_labels,\n",
    "                      'base':base})\n",
    "    b = error_base.groupby('labels').sum()\n",
    "    error_rates = pd.DataFrame((b['errors']/b['base']).sort_values(ascending=False), columns=['Error Rate'])\n",
    "    error_rates['Total Session Counts'] = b['base']\n",
    "    return error_rates\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    classes = label_lookup.values()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "load_data()\n",
    "create_sessions()\n",
    "Y, labels = gather_target_vars()\n",
    "X,scaler = feature_engineering()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y.as_matrix(), test_size=0.33, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0010 cost= 1.565006971\n",
      "Epoch: 0020 cost= 1.402346969\n",
      "Epoch: 0030 cost= 1.296683788\n",
      "Epoch: 0040 cost= 1.222968221\n",
      "Epoch: 0050 cost= 1.168118477\n",
      "Epoch: 0060 cost= 1.125343323\n",
      "Epoch: 0070 cost= 1.090854168\n",
      "Epoch: 0080 cost= 1.062356591\n",
      "Epoch: 0090 cost= 1.038365960\n",
      "Epoch: 0100 cost= 1.017859697\n",
      "Epoch: 0110 cost= 1.000106812\n",
      "Epoch: 0120 cost= 0.984566748\n",
      "Epoch: 0130 cost= 0.970830500\n",
      "Epoch: 0140 cost= 0.958582640\n",
      "Epoch: 0150 cost= 0.947575808\n",
      "Epoch: 0160 cost= 0.937612474\n",
      "Epoch: 0170 cost= 0.928534746\n",
      "Epoch: 0180 cost= 0.920215905\n",
      "Epoch: 0190 cost= 0.912549317\n",
      "Epoch: 0200 cost= 0.905449390\n",
      "Epoch: 0210 cost= 0.898843169\n",
      "Epoch: 0220 cost= 0.892671406\n",
      "Epoch: 0230 cost= 0.886881351\n",
      "Epoch: 0240 cost= 0.881430387\n",
      "Epoch: 0250 cost= 0.876282036\n",
      "Epoch: 0260 cost= 0.871404231\n",
      "Epoch: 0270 cost= 0.866769373\n",
      "Epoch: 0280 cost= 0.862355173\n",
      "Epoch: 0290 cost= 0.858139038\n",
      "Epoch: 0300 cost= 0.854103982\n",
      "Epoch: 0310 cost= 0.850233912\n",
      "Epoch: 0320 cost= 0.846514046\n",
      "Epoch: 0330 cost= 0.842933714\n",
      "Epoch: 0340 cost= 0.839480460\n",
      "Epoch: 0350 cost= 0.836145282\n",
      "Epoch: 0360 cost= 0.832919717\n",
      "Epoch: 0370 cost= 0.829795361\n",
      "Epoch: 0380 cost= 0.826764941\n",
      "Epoch: 0390 cost= 0.823822498\n",
      "Epoch: 0400 cost= 0.820962965\n",
      "Epoch: 0410 cost= 0.818180263\n",
      "Epoch: 0420 cost= 0.815469742\n",
      "Epoch: 0430 cost= 0.812827528\n",
      "Epoch: 0440 cost= 0.810249448\n",
      "Epoch: 0450 cost= 0.807732284\n",
      "Epoch: 0460 cost= 0.805272400\n",
      "Epoch: 0470 cost= 0.802868009\n",
      "Epoch: 0480 cost= 0.800513804\n",
      "Epoch: 0490 cost= 0.798209369\n",
      "Epoch: 0500 cost= 0.795951962\n",
      "Epoch: 0510 cost= 0.793738723\n",
      "Epoch: 0520 cost= 0.791568160\n",
      "Epoch: 0530 cost= 0.789438665\n",
      "Epoch: 0540 cost= 0.787348330\n",
      "Epoch: 0550 cost= 0.785295427\n",
      "Epoch: 0560 cost= 0.783278644\n",
      "Epoch: 0570 cost= 0.781296372\n",
      "Epoch: 0580 cost= 0.779346704\n",
      "Epoch: 0590 cost= 0.777430117\n",
      "Epoch: 0600 cost= 0.775543571\n",
      "Epoch: 0610 cost= 0.773687601\n",
      "Epoch: 0620 cost= 0.771860301\n",
      "Epoch: 0630 cost= 0.770060658\n",
      "Epoch: 0640 cost= 0.768288136\n",
      "Epoch: 0650 cost= 0.766542256\n",
      "Epoch: 0660 cost= 0.764820755\n",
      "Epoch: 0670 cost= 0.763124466\n",
      "Epoch: 0680 cost= 0.761451662\n",
      "Epoch: 0690 cost= 0.759802401\n",
      "Epoch: 0700 cost= 0.758175194\n",
      "Epoch: 0710 cost= 0.756570041\n",
      "Epoch: 0720 cost= 0.754986882\n",
      "Epoch: 0730 cost= 0.753423989\n",
      "Epoch: 0740 cost= 0.751881361\n",
      "Epoch: 0750 cost= 0.750357449\n",
      "Epoch: 0760 cost= 0.748855174\n",
      "Epoch: 0770 cost= 0.747370005\n",
      "Epoch: 0780 cost= 0.745903015\n",
      "Epoch: 0790 cost= 0.744454443\n",
      "Epoch: 0800 cost= 0.743023455\n",
      "Epoch: 0810 cost= 0.741610050\n",
      "Epoch: 0820 cost= 0.740212679\n",
      "Epoch: 0830 cost= 0.738831997\n",
      "Epoch: 0840 cost= 0.737467349\n",
      "Epoch: 0850 cost= 0.736117959\n",
      "Epoch: 0860 cost= 0.734784722\n",
      "Epoch: 0870 cost= 0.733466625\n",
      "Epoch: 0880 cost= 0.732162654\n",
      "Epoch: 0890 cost= 0.730873466\n",
      "Epoch: 0900 cost= 0.729598522\n",
      "Epoch: 0910 cost= 0.728337646\n",
      "Epoch: 0920 cost= 0.727091014\n",
      "Epoch: 0930 cost= 0.725856602\n",
      "Epoch: 0940 cost= 0.724635720\n",
      "Epoch: 0950 cost= 0.723428071\n",
      "Epoch: 0960 cost= 0.722233236\n",
      "Epoch: 0970 cost= 0.721050262\n",
      "Epoch: 0980 cost= 0.719880760\n",
      "Epoch: 0990 cost= 0.718722224\n",
      "Epoch: 1000 cost= 0.717575848\n",
      "Optimization Finished!\n",
      "Accuracy: 0.770902\n",
      "0.770902\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import shutil\n",
    "import os.path\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 1000\n",
    "batch_size = 100\n",
    "display_step = 10\n",
    "\n",
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    # Create the model\n",
    "    \n",
    "    # tf Graph Input\n",
    "    x = tf.placeholder(tf.float32, [None, 51]) # 3 inputs\n",
    "    y = tf.placeholder(tf.float32, [None, 6]) # 6 classes\n",
    "\n",
    "    # Set model weights\n",
    "    W = tf.Variable(tf.zeros([51, 6]))\n",
    "    b = tf.Variable(tf.zeros([6]))\n",
    "\n",
    "    # Construct model\n",
    "    pred = tf.nn.softmax(tf.matmul(x, W) + b) # Softmax\n",
    "\n",
    "    # Minimize error using cross entropy\n",
    "    cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=1))\n",
    "    # Gradient Descent\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "    # Initializing the variables\n",
    "    init = tf.initialize_all_variables()\n",
    "    \n",
    "    \n",
    "    sess = tf.Session()\n",
    "\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        _, c = sess.run([optimizer, cost], feed_dict={x: X_train,y: Y_train})\n",
    "        \n",
    "        # Compute average loss\n",
    "        #avg_cost += c / total_batch\n",
    "        # Display logs per epoch step\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            print \"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(c)\n",
    "\n",
    "    print \"Optimization Finished!\"\n",
    "\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy for 3000 examples\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print \"Accuracy:\", accuracy.eval({x: X_test, y: Y_test}, sess)\n",
    "\n",
    "# Store variable\n",
    "_W = W.eval(sess)\n",
    "_b = b.eval(sess)\n",
    "\n",
    "\n",
    "sess.close()\n",
    "\n",
    "#Create new graph for exporting\n",
    "g_2 = tf.Graph()\n",
    "with g_2.as_default():\n",
    "    # Reconstruct graph\n",
    "    x_2 = tf.placeholder(\"float\", [None, 51], name=\"input\")\n",
    "    W_2 = tf.constant(_W, name=\"constant_W\")\n",
    "    b_2 = tf.constant(_b, name=\"constant_b\")\n",
    "    y_2 = tf.nn.softmax(tf.matmul(x_2, W_2) + b_2, name=\"output\")\n",
    "\n",
    "    sess_2 = tf.Session()\n",
    "\n",
    "    init_2 = tf.initialize_all_variables();\n",
    "    sess_2.run(init_2)\n",
    "\n",
    "    \n",
    "    graph_def = g_2.as_graph_def()\n",
    "    \n",
    "    tf.train.write_graph(graph_def, 'Models','activityModelLR.pb', as_text=False)\n",
    "\n",
    "    # Test trained model\n",
    "    y__2 = tf.placeholder(\"float\", [None, 6])\n",
    "    correct_prediction_2 = tf.equal(tf.argmax(y_2, 1), tf.argmax(y__2, 1))\n",
    "    accuracy_2 = tf.reduce_mean(tf.cast(correct_prediction_2, \"float\"))\n",
    "    print(accuracy_2.eval({x_2: X_test, y__2: Y_test}, sess_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0005 cost= 1032.783569336\n",
      "Epoch: 0010 cost= 772.242614746\n",
      "Epoch: 0015 cost= 588.952575684\n",
      "Epoch: 0020 cost= 471.314880371\n",
      "Epoch: 0025 cost= 386.303588867\n",
      "Epoch: 0030 cost= 318.476348877\n",
      "Epoch: 0035 cost= 262.130615234\n",
      "Epoch: 0040 cost= 216.910949707\n",
      "Epoch: 0045 cost= 179.391952515\n",
      "Epoch: 0050 cost= 149.126266479\n",
      "Epoch: 0055 cost= 126.199195862\n",
      "Epoch: 0060 cost= 107.779678345\n",
      "Epoch: 0065 cost= 94.188552856\n",
      "Epoch: 0070 cost= 84.890579224\n",
      "Epoch: 0075 cost= 77.752685547\n",
      "Epoch: 0080 cost= 71.332267761\n",
      "Epoch: 0085 cost= 65.772644043\n",
      "Epoch: 0090 cost= 61.178318024\n",
      "Epoch: 0095 cost= 57.208366394\n",
      "Epoch: 0100 cost= 53.544254303\n",
      "Epoch: 0105 cost= 50.242332458\n",
      "Epoch: 0110 cost= 47.363910675\n",
      "Epoch: 0115 cost= 44.791553497\n",
      "Epoch: 0120 cost= 42.446357727\n",
      "Epoch: 0125 cost= 40.342063904\n",
      "Epoch: 0130 cost= 38.489135742\n",
      "Epoch: 0135 cost= 36.827781677\n",
      "Epoch: 0140 cost= 35.344345093\n",
      "Epoch: 0145 cost= 33.971736908\n",
      "Epoch: 0150 cost= 32.691791534\n",
      "Epoch: 0155 cost= 31.494247437\n",
      "Epoch: 0160 cost= 30.392204285\n",
      "Epoch: 0165 cost= 29.351730347\n",
      "Epoch: 0170 cost= 28.375799179\n",
      "Epoch: 0175 cost= 27.458295822\n",
      "Epoch: 0180 cost= 26.596683502\n",
      "Epoch: 0185 cost= 25.783231735\n",
      "Epoch: 0190 cost= 25.004131317\n",
      "Epoch: 0195 cost= 24.254526138\n",
      "Epoch: 0200 cost= 23.537141800\n",
      "Epoch: 0205 cost= 22.869590759\n",
      "Epoch: 0210 cost= 22.250246048\n",
      "Epoch: 0215 cost= 21.663581848\n",
      "Epoch: 0220 cost= 21.111995697\n",
      "Epoch: 0225 cost= 20.585655212\n",
      "Epoch: 0230 cost= 20.077058792\n",
      "Epoch: 0235 cost= 19.582197189\n",
      "Epoch: 0240 cost= 19.100252151\n",
      "Epoch: 0245 cost= 18.636098862\n",
      "Epoch: 0250 cost= 18.199806213\n",
      "Epoch: 0255 cost= 17.779014587\n",
      "Epoch: 0260 cost= 17.374732971\n",
      "Epoch: 0265 cost= 16.981863022\n",
      "Epoch: 0270 cost= 16.601470947\n",
      "Epoch: 0275 cost= 16.235740662\n",
      "Epoch: 0280 cost= 15.880410194\n",
      "Epoch: 0285 cost= 15.540378571\n",
      "Epoch: 0290 cost= 15.212518692\n",
      "Epoch: 0295 cost= 14.894360542\n",
      "Epoch: 0300 cost= 14.586064339\n",
      "Epoch: 0305 cost= 14.286317825\n",
      "Epoch: 0310 cost= 13.992302895\n",
      "Epoch: 0315 cost= 13.710745811\n",
      "Epoch: 0320 cost= 13.448269844\n",
      "Epoch: 0325 cost= 13.176816940\n",
      "Epoch: 0330 cost= 12.925165176\n",
      "Epoch: 0335 cost= 12.679443359\n",
      "Epoch: 0340 cost= 12.448447227\n",
      "Epoch: 0345 cost= 12.232840538\n",
      "Epoch: 0350 cost= 12.018815041\n",
      "Epoch: 0355 cost= 11.816046715\n",
      "Epoch: 0360 cost= 11.620629311\n",
      "Epoch: 0365 cost= 11.417055130\n",
      "Epoch: 0370 cost= 11.237813950\n",
      "Epoch: 0375 cost= 11.051497459\n",
      "Epoch: 0380 cost= 10.885268211\n",
      "Epoch: 0385 cost= 10.702246666\n",
      "Epoch: 0390 cost= 10.534976959\n",
      "Epoch: 0395 cost= 10.363748550\n",
      "Epoch: 0400 cost= 10.208486557\n",
      "Epoch: 0405 cost= 10.065418243\n",
      "Epoch: 0410 cost= 9.888698578\n",
      "Epoch: 0415 cost= 9.753075600\n",
      "Epoch: 0420 cost= 9.626887321\n",
      "Epoch: 0425 cost= 9.456718445\n",
      "Epoch: 0430 cost= 9.314064026\n",
      "Epoch: 0435 cost= 9.167655945\n",
      "Epoch: 0440 cost= 9.030187607\n",
      "Epoch: 0445 cost= 8.892831802\n",
      "Epoch: 0450 cost= 8.761917114\n",
      "Epoch: 0455 cost= 8.632843018\n",
      "Epoch: 0460 cost= 8.507134438\n",
      "Epoch: 0465 cost= 8.384546280\n",
      "Epoch: 0470 cost= 8.265064240\n",
      "Epoch: 0475 cost= 8.148497581\n",
      "Epoch: 0480 cost= 8.034634590\n",
      "Epoch: 0485 cost= 7.922577858\n",
      "Epoch: 0490 cost= 7.812711716\n",
      "Epoch: 0495 cost= 7.704573631\n",
      "Epoch: 0500 cost= 7.598705769\n",
      "Epoch: 0505 cost= 7.494224548\n",
      "Epoch: 0510 cost= 7.391243935\n",
      "Epoch: 0515 cost= 7.289550304\n",
      "Epoch: 0520 cost= 7.189334393\n",
      "Epoch: 0525 cost= 7.089978218\n",
      "Epoch: 0530 cost= 6.991626740\n",
      "Epoch: 0535 cost= 6.897498608\n",
      "Epoch: 0540 cost= 6.801414967\n",
      "Epoch: 0545 cost= 6.738637924\n",
      "Epoch: 0550 cost= 6.636456966\n",
      "Epoch: 0555 cost= 6.534252644\n",
      "Epoch: 0560 cost= 6.461081982\n",
      "Epoch: 0565 cost= 6.382767200\n",
      "Epoch: 0570 cost= 6.333369255\n",
      "Epoch: 0575 cost= 6.218777657\n",
      "Epoch: 0580 cost= 6.119481087\n",
      "Epoch: 0585 cost= 6.042017460\n",
      "Epoch: 0590 cost= 5.956012249\n",
      "Epoch: 0595 cost= 5.879042625\n",
      "Epoch: 0600 cost= 5.806366444\n",
      "Epoch: 0605 cost= 5.754866600\n",
      "Epoch: 0610 cost= 5.705831051\n",
      "Epoch: 0615 cost= 5.623004436\n",
      "Epoch: 0620 cost= 5.559116364\n",
      "Epoch: 0625 cost= 5.493349552\n",
      "Epoch: 0630 cost= 5.412551880\n",
      "Epoch: 0635 cost= 5.350264549\n",
      "Epoch: 0640 cost= 5.307605267\n",
      "Epoch: 0645 cost= 5.218461990\n",
      "Epoch: 0650 cost= 5.178302288\n",
      "Epoch: 0655 cost= 5.095358849\n",
      "Epoch: 0660 cost= 5.050536633\n",
      "Epoch: 0665 cost= 4.963114262\n",
      "Epoch: 0670 cost= 4.916020870\n",
      "Epoch: 0675 cost= 4.845127583\n",
      "Epoch: 0680 cost= 4.833030701\n",
      "Epoch: 0685 cost= 4.752184391\n",
      "Epoch: 0690 cost= 4.722861767\n",
      "Epoch: 0695 cost= 4.614389420\n",
      "Epoch: 0700 cost= 4.563227654\n",
      "Epoch: 0705 cost= 4.506741524\n",
      "Epoch: 0710 cost= 4.434638500\n",
      "Epoch: 0715 cost= 4.386387825\n",
      "Epoch: 0720 cost= 4.331614494\n",
      "Epoch: 0725 cost= 4.303899765\n",
      "Epoch: 0730 cost= 4.238837242\n",
      "Epoch: 0735 cost= 4.179426193\n",
      "Epoch: 0740 cost= 4.121562004\n",
      "Epoch: 0745 cost= 4.094131470\n",
      "Epoch: 0750 cost= 4.040512085\n",
      "Epoch: 0755 cost= 3.971073866\n",
      "Epoch: 0760 cost= 3.917055607\n",
      "Epoch: 0765 cost= 3.901921988\n",
      "Epoch: 0770 cost= 3.814089775\n",
      "Epoch: 0775 cost= 3.804787397\n",
      "Epoch: 0780 cost= 3.738619804\n",
      "Epoch: 0785 cost= 3.682454586\n",
      "Epoch: 0790 cost= 3.642152309\n",
      "Epoch: 0795 cost= 3.589500904\n",
      "Epoch: 0800 cost= 3.580498695\n",
      "Epoch: 0805 cost= 3.539763212\n",
      "Epoch: 0810 cost= 3.450536013\n",
      "Epoch: 0815 cost= 3.408420086\n",
      "Epoch: 0820 cost= 3.386655807\n",
      "Epoch: 0825 cost= 3.318473101\n",
      "Epoch: 0830 cost= 3.272993088\n",
      "Epoch: 0835 cost= 3.233102083\n",
      "Epoch: 0840 cost= 3.211814880\n",
      "Epoch: 0845 cost= 3.172985792\n",
      "Epoch: 0850 cost= 3.172017336\n",
      "Epoch: 0855 cost= 3.147634029\n",
      "Epoch: 0860 cost= 3.063397884\n",
      "Epoch: 0865 cost= 3.028513193\n",
      "Epoch: 0870 cost= 2.999265432\n",
      "Epoch: 0875 cost= 2.977187872\n",
      "Epoch: 0880 cost= 2.917147875\n",
      "Epoch: 0885 cost= 2.859644413\n",
      "Epoch: 0890 cost= 2.834233046\n",
      "Epoch: 0895 cost= 2.829424143\n",
      "Epoch: 0900 cost= 2.779110432\n",
      "Epoch: 0905 cost= 2.736534595\n",
      "Epoch: 0910 cost= 2.686854124\n",
      "Epoch: 0915 cost= 2.669718266\n",
      "Epoch: 0920 cost= 2.638499975\n",
      "Epoch: 0925 cost= 2.602406740\n",
      "Epoch: 0930 cost= 2.566675663\n",
      "Epoch: 0935 cost= 2.538681269\n",
      "Epoch: 0940 cost= 2.505502224\n",
      "Epoch: 0945 cost= 2.484629154\n",
      "Epoch: 0950 cost= 2.439601898\n",
      "Epoch: 0955 cost= 2.482171059\n",
      "Epoch: 0960 cost= 2.421644926\n",
      "Epoch: 0965 cost= 2.399026871\n",
      "Epoch: 0970 cost= 2.311069489\n",
      "Epoch: 0975 cost= 2.323088884\n",
      "Epoch: 0980 cost= 2.289405107\n",
      "Epoch: 0985 cost= 2.255448818\n",
      "Epoch: 0990 cost= 2.204027653\n",
      "Epoch: 0995 cost= 2.163655996\n",
      "Epoch: 1000 cost= 2.162874699\n",
      "Epoch: 1005 cost= 2.119316578\n",
      "Epoch: 1010 cost= 2.113138914\n",
      "Epoch: 1015 cost= 2.082614422\n",
      "Epoch: 1020 cost= 2.053617954\n",
      "Epoch: 1025 cost= 2.033531666\n",
      "Epoch: 1030 cost= 2.024354219\n",
      "Epoch: 1035 cost= 2.001987696\n",
      "Epoch: 1040 cost= 1.974427342\n",
      "Epoch: 1045 cost= 1.918313026\n",
      "Epoch: 1050 cost= 1.872138858\n",
      "Epoch: 1055 cost= 1.849885821\n",
      "Epoch: 1060 cost= 1.851145506\n",
      "Epoch: 1065 cost= 1.814531446\n",
      "Epoch: 1070 cost= 1.795579672\n",
      "Epoch: 1075 cost= 1.769296527\n",
      "Epoch: 1080 cost= 1.742025495\n",
      "Epoch: 1085 cost= 1.707281590\n",
      "Epoch: 1090 cost= 1.675355315\n",
      "Epoch: 1095 cost= 1.652804017\n",
      "Epoch: 1100 cost= 1.642666221\n",
      "Epoch: 1105 cost= 1.634857416\n",
      "Epoch: 1110 cost= 1.671010375\n",
      "Epoch: 1115 cost= 1.598634481\n",
      "Epoch: 1120 cost= 1.564191580\n",
      "Epoch: 1125 cost= 1.566954017\n",
      "Epoch: 1130 cost= 1.529981136\n",
      "Epoch: 1135 cost= 1.531996369\n",
      "Epoch: 1140 cost= 1.549025178\n",
      "Epoch: 1145 cost= 1.510360122\n",
      "Epoch: 1150 cost= 1.499022126\n",
      "Epoch: 1155 cost= 1.411175251\n",
      "Epoch: 1160 cost= 1.428793788\n",
      "Epoch: 1165 cost= 1.393727303\n",
      "Epoch: 1170 cost= 1.429469943\n",
      "Epoch: 1175 cost= 1.364484310\n",
      "Epoch: 1180 cost= 1.337908864\n",
      "Epoch: 1185 cost= 1.299728036\n",
      "Epoch: 1190 cost= 1.318476796\n",
      "Epoch: 1195 cost= 1.263112187\n",
      "Epoch: 1200 cost= 1.244084358\n",
      "Epoch: 1205 cost= 1.225983620\n",
      "Epoch: 1210 cost= 1.216221690\n",
      "Epoch: 1215 cost= 1.226874471\n",
      "Epoch: 1220 cost= 1.214105606\n",
      "Epoch: 1225 cost= 1.201493859\n",
      "Epoch: 1230 cost= 1.180709362\n",
      "Epoch: 1235 cost= 1.172521591\n",
      "Epoch: 1240 cost= 1.164188623\n",
      "Epoch: 1245 cost= 1.151862502\n",
      "Epoch: 1250 cost= 1.183851719\n",
      "Epoch: 1255 cost= 1.122935534\n",
      "Epoch: 1260 cost= 1.105587959\n",
      "Epoch: 1265 cost= 1.092711449\n",
      "Epoch: 1270 cost= 1.090816617\n",
      "Epoch: 1275 cost= 1.054605842\n",
      "Epoch: 1280 cost= 1.086466074\n",
      "Epoch: 1285 cost= 1.037483573\n",
      "Epoch: 1290 cost= 1.022683263\n",
      "Epoch: 1295 cost= 1.025533676\n",
      "Epoch: 1300 cost= 0.970981181\n",
      "Epoch: 1305 cost= 1.020523310\n",
      "Epoch: 1310 cost= 1.009323001\n",
      "Epoch: 1315 cost= 0.971700728\n",
      "Epoch: 1320 cost= 0.941382408\n",
      "Epoch: 1325 cost= 0.922529280\n",
      "Epoch: 1330 cost= 0.926540136\n",
      "Epoch: 1335 cost= 0.909268975\n",
      "Epoch: 1340 cost= 0.936083734\n",
      "Epoch: 1345 cost= 0.882939339\n",
      "Epoch: 1350 cost= 0.867654026\n",
      "Epoch: 1355 cost= 0.907151580\n",
      "Epoch: 1360 cost= 0.870382845\n",
      "Epoch: 1365 cost= 0.868207335\n",
      "Epoch: 1370 cost= 0.867204964\n",
      "Epoch: 1375 cost= 0.818598688\n",
      "Epoch: 1380 cost= 0.814161360\n",
      "Epoch: 1385 cost= 0.819413900\n",
      "Epoch: 1390 cost= 0.805867136\n",
      "Epoch: 1395 cost= 0.784382880\n",
      "Epoch: 1400 cost= 0.818612933\n",
      "Epoch: 1405 cost= 0.775174022\n",
      "Epoch: 1410 cost= 0.804222226\n",
      "Epoch: 1415 cost= 0.758037329\n",
      "Epoch: 1420 cost= 0.744428217\n",
      "Epoch: 1425 cost= 0.749652982\n",
      "Epoch: 1430 cost= 0.697402954\n",
      "Epoch: 1435 cost= 0.719965219\n",
      "Epoch: 1440 cost= 0.745538116\n",
      "Epoch: 1445 cost= 0.735289633\n",
      "Epoch: 1450 cost= 0.708339751\n",
      "Epoch: 1455 cost= 0.702492774\n",
      "Epoch: 1460 cost= 0.663755059\n",
      "Epoch: 1465 cost= 0.693308711\n",
      "Epoch: 1470 cost= 0.711569011\n",
      "Epoch: 1475 cost= 0.676423669\n",
      "Epoch: 1480 cost= 0.642094910\n",
      "Epoch: 1485 cost= 0.624000013\n",
      "Epoch: 1490 cost= 0.607525587\n",
      "Epoch: 1495 cost= 0.609331608\n",
      "Epoch: 1500 cost= 0.598906696\n",
      "Epoch: 1505 cost= 0.590971649\n",
      "Epoch: 1510 cost= 0.614741623\n",
      "Epoch: 1515 cost= 0.554307997\n",
      "Epoch: 1520 cost= 0.578962386\n",
      "Epoch: 1525 cost= 0.608871281\n",
      "Epoch: 1530 cost= 0.648139715\n",
      "Epoch: 1535 cost= 0.542769969\n",
      "Epoch: 1540 cost= 0.570672035\n",
      "Epoch: 1545 cost= 0.534585297\n",
      "Epoch: 1550 cost= 0.587957323\n",
      "Epoch: 1555 cost= 0.521834195\n",
      "Epoch: 1560 cost= 0.591703415\n",
      "Epoch: 1565 cost= 0.535252333\n",
      "Epoch: 1570 cost= 0.509560227\n",
      "Epoch: 1575 cost= 0.494834691\n",
      "Epoch: 1580 cost= 0.559992313\n",
      "Epoch: 1585 cost= 0.488957494\n",
      "Epoch: 1590 cost= 0.510975838\n",
      "Epoch: 1595 cost= 0.470502138\n",
      "Epoch: 1600 cost= 0.512487471\n",
      "Epoch: 1605 cost= 0.478428125\n",
      "Epoch: 1610 cost= 0.490131259\n",
      "Epoch: 1615 cost= 0.481068552\n",
      "Epoch: 1620 cost= 0.479219288\n",
      "Epoch: 1625 cost= 0.431525856\n",
      "Epoch: 1630 cost= 0.435254306\n",
      "Epoch: 1635 cost= 0.442341805\n",
      "Epoch: 1640 cost= 0.397407502\n",
      "Epoch: 1645 cost= 0.424721003\n",
      "Epoch: 1650 cost= 0.423410594\n",
      "Epoch: 1655 cost= 0.460646003\n",
      "Epoch: 1660 cost= 0.512285829\n",
      "Epoch: 1665 cost= 0.402455807\n",
      "Epoch: 1670 cost= 0.419116110\n",
      "Epoch: 1675 cost= 0.392039120\n",
      "Epoch: 1680 cost= 0.416948348\n",
      "Epoch: 1685 cost= 0.432608664\n",
      "Epoch: 1690 cost= 0.359069288\n",
      "Epoch: 1695 cost= 0.381225079\n",
      "Epoch: 1700 cost= 0.377005517\n",
      "Epoch: 1705 cost= 0.375452310\n",
      "Epoch: 1710 cost= 0.370271534\n",
      "Epoch: 1715 cost= 0.350095898\n",
      "Epoch: 1720 cost= 0.352470607\n",
      "Epoch: 1725 cost= 0.402305514\n",
      "Epoch: 1730 cost= 0.369046181\n",
      "Epoch: 1735 cost= 0.336405307\n",
      "Epoch: 1740 cost= 0.350763798\n",
      "Epoch: 1745 cost= 0.356867224\n",
      "Epoch: 1750 cost= 0.421708673\n",
      "Epoch: 1755 cost= 0.345161408\n",
      "Epoch: 1760 cost= 0.338509411\n",
      "Epoch: 1765 cost= 0.326010138\n",
      "Epoch: 1770 cost= 0.316786200\n",
      "Epoch: 1775 cost= 0.302850604\n",
      "Epoch: 1780 cost= 0.315357685\n",
      "Epoch: 1785 cost= 0.305208057\n",
      "Epoch: 1790 cost= 0.308481038\n",
      "Epoch: 1795 cost= 0.322337985\n",
      "Epoch: 1800 cost= 0.282098353\n",
      "Epoch: 1805 cost= 0.295064360\n",
      "Epoch: 1810 cost= 0.329199165\n",
      "Epoch: 1815 cost= 0.365985781\n",
      "Epoch: 1820 cost= 0.295743793\n",
      "Epoch: 1825 cost= 0.293510675\n",
      "Epoch: 1830 cost= 0.271765113\n",
      "Epoch: 1835 cost= 0.289475173\n",
      "Epoch: 1840 cost= 0.312984347\n",
      "Epoch: 1845 cost= 0.273787171\n",
      "Epoch: 1850 cost= 0.254756421\n",
      "Epoch: 1855 cost= 0.302696794\n",
      "Epoch: 1860 cost= 0.313660949\n",
      "Epoch: 1865 cost= 0.290556967\n",
      "Epoch: 1870 cost= 0.298093081\n",
      "Epoch: 1875 cost= 0.248465374\n",
      "Epoch: 1880 cost= 0.220697835\n",
      "Epoch: 1885 cost= 0.249993786\n",
      "Epoch: 1890 cost= 0.234393790\n",
      "Epoch: 1895 cost= 0.236770377\n",
      "Epoch: 1900 cost= 0.273998857\n",
      "Epoch: 1905 cost= 0.248911515\n",
      "Epoch: 1910 cost= 0.222135961\n",
      "Epoch: 1915 cost= 0.229329020\n",
      "Epoch: 1920 cost= 0.218682170\n",
      "Epoch: 1925 cost= 0.243347824\n",
      "Epoch: 1930 cost= 0.252575636\n",
      "Epoch: 1935 cost= 0.214470059\n",
      "Epoch: 1940 cost= 0.193669930\n",
      "Epoch: 1945 cost= 0.234816656\n",
      "Epoch: 1950 cost= 0.234144062\n",
      "Epoch: 1955 cost= 0.252650112\n",
      "Epoch: 1960 cost= 0.297657788\n",
      "Epoch: 1965 cost= 0.218430862\n",
      "Epoch: 1970 cost= 0.227129698\n",
      "Epoch: 1975 cost= 0.173611104\n",
      "Epoch: 1980 cost= 0.185772374\n",
      "Epoch: 1985 cost= 0.257507414\n",
      "Epoch: 1990 cost= 0.195628509\n",
      "Epoch: 1995 cost= 0.242323071\n",
      "Epoch: 2000 cost= 0.171287134\n",
      "Optimization Finished!\n",
      "Accuracy: 0.874037\n",
      "0.874037\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import shutil\n",
    "import os.path\n",
    "\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 2000\n",
    "batch_size = 500\n",
    "display_step = 5\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 200 # 1st layer number of features\n",
    "n_hidden_2 = 200 # 2nd layer number of features\n",
    "n_input = 51 # Number of inputs\n",
    "n_classes = 6 # Number of classes\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    # model inputs\n",
    "    x = tf.placeholder(\"float\", shape=[None, n_input])\n",
    "    y = tf.placeholder(\"float\", shape=[None, n_classes])\n",
    "    \n",
    "    # set model weights\n",
    "    W_h1 = tf.Variable(tf.random_normal([n_input, n_hidden_1]))\n",
    "    W_h2 = tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2]))\n",
    "    W_out = tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "    \n",
    "    # set model biases\n",
    "    b1 = tf.Variable(tf.random_normal([n_hidden_1]))\n",
    "    b2 = tf.Variable(tf.random_normal([n_hidden_2]))\n",
    "    b_out = tf.Variable(tf.random_normal([n_classes]))\n",
    "    \n",
    "    # Construct Model\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_1 = tf.add(tf.matmul(x, W_h1), b1)\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, W_h2), b2)\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    # Output layer with linear activation\n",
    "    pred = tf.matmul(layer_2, W_out) + b_out\n",
    "    \n",
    "    # Define loss and optimizer\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    \n",
    "    # Initializing the variables\n",
    "    init = tf.initialize_all_variables()\n",
    "    \n",
    "    sess = tf.Session()\n",
    "\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        _, c = sess.run([optimizer, cost], feed_dict={x: X_train,y: Y_train})\n",
    "        \n",
    "        # Compute average loss\n",
    "        #avg_cost += c / total_batch\n",
    "        # Display logs per epoch step\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            print \"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(c)\n",
    "\n",
    "    print \"Optimization Finished!\"\n",
    "\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy for 3000 examples\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print \"Accuracy:\", accuracy.eval({x: X_test, y: Y_test}, sess)\n",
    "\n",
    "# Store Variable\n",
    "_W_h1 = W_h1.eval(sess)\n",
    "_W_h2 = W_h2.eval(sess)\n",
    "_W_out =W_out.eval(sess)\n",
    "\n",
    "_b1 = b1.eval(sess)\n",
    "_b2 = b2.eval(sess)\n",
    "_b_out = b_out.eval(sess)\n",
    "\n",
    "sess.close()\n",
    "\n",
    "# create a new graph for exporting\n",
    "g_2 = tf.Graph()\n",
    "with g_2.as_default():\n",
    "    # Reconstruct Graph\n",
    "    # model inputs\n",
    "    x_2 = tf.placeholder(\"float\", shape=[None, n_input], name=\"input\")\n",
    "    \n",
    "    \n",
    "    # set model weights\n",
    "    W_2_h1 = tf.constant(_W_h1, name=\"constant_W_h1\")\n",
    "    W_2_h2 = tf.constant(_W_h2, name=\"constant_W_h2\")\n",
    "    W_2_out = tf.constant(_W_out, name=\"constant_W_out\")\n",
    "    \n",
    "    # set model biases\n",
    "    b_2_1 = tf.constant(_b1, name=\"constant_b1\")\n",
    "    b_2_2 = tf.constant(_b2, name=\"constant_b2\")\n",
    "    b_2_out = tf.constant(_b_out, name=\"constant_b_out\")\n",
    "    \n",
    "    # Construct Model\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_2_1 = tf.add(tf.matmul(x_2, W_2_h1), b_2_1)\n",
    "    layer_2_1 = tf.nn.relu(layer_2_1)\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_2_2 = tf.add(tf.matmul(layer_2_1, W_2_h2), b_2_2)\n",
    "    layer_2_2 = tf.nn.relu(layer_2_2)\n",
    "    \n",
    "    # Output layer with linear activation\n",
    "    y_2 = tf.nn.bias_add(tf.matmul(layer_2_2, W_2_out), b_2_out, name=\"output\")\n",
    "    \n",
    "    #y_2.name = \"output\"\n",
    "    \n",
    "    sess_2 = tf.Session()\n",
    "\n",
    "    init_2 = tf.initialize_all_variables();\n",
    "    sess_2.run(init_2)\n",
    "\n",
    "    \n",
    "    graph_def = g_2.as_graph_def()\n",
    "    \n",
    "    tf.train.write_graph(graph_def, 'Models','activityModelMLP2.pb', as_text=False)\n",
    "\n",
    "    # Test trained model\n",
    "    y__2 = tf.placeholder(\"float\", [None, 6])\n",
    "    correct_prediction_2 = tf.equal(tf.argmax(y_2, 1), tf.argmax(y__2, 1))\n",
    "    accuracy_2 = tf.reduce_mean(tf.cast(correct_prediction_2, \"float\"))\n",
    "    print(accuracy_2.eval({x_2: X_test, y__2: Y_test}, sess_2))\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_X_test = pd.DataFrame(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_X_test.to_csv('test_input.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_Y_test = pd.DataFrame(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_Y_test.to_csv('test_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x-accel</th>\n",
       "      <th>y-accel</th>\n",
       "      <th>z-accel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>941963</th>\n",
       "      <td>0.69</td>\n",
       "      <td>10.80</td>\n",
       "      <td>-2.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941964</th>\n",
       "      <td>6.85</td>\n",
       "      <td>7.44</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941965</th>\n",
       "      <td>0.93</td>\n",
       "      <td>5.63</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941966</th>\n",
       "      <td>-2.11</td>\n",
       "      <td>5.01</td>\n",
       "      <td>-0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941967</th>\n",
       "      <td>-4.59</td>\n",
       "      <td>4.29</td>\n",
       "      <td>-1.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        x-accel  y-accel  z-accel\n",
       "941963     0.69    10.80    -2.03\n",
       "941964     6.85     7.44    -0.50\n",
       "941965     0.93     5.63    -0.50\n",
       "941966    -2.11     5.01    -0.69\n",
       "941967    -4.59     4.29    -1.95"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accel_cols = ['x-accel','y-accel','z-accel']\n",
    "g = actitracker.loc[:,accel_cols+['user','session']]\n",
    "g = g[g.user == 1]\n",
    "g = g[g.session == 1]\n",
    "df_sample_raw_inputs =  g[accel_cols]\n",
    "df_sample_raw_inputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sample_raw_inputs.to_csv('raw_input.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# accel_cols = ['x-accel','y-accel','z-accel']\n",
    "# g = actitracker.loc[:,accel_cols+['user','session']]\n",
    "# g = g[g.user == 1]\n",
    "# g = g[g.session == 1]\n",
    "# g = g.loc[:,accel_cols+['user','session']].groupby(['user','session'])\n",
    "\n",
    "# def iqr(x):\n",
    "# #         ''' calculate IQR from array\n",
    "# #         '''\n",
    "#         q75, q25 = np.percentile(x, [75,25])\n",
    "#         return q75-q25\n",
    "\n",
    "\n",
    "\n",
    "# means = g[accel_cols].apply(lambda x: np.mean(x))\n",
    "# sds = g[accel_cols].apply(lambda x: np.std(x))\n",
    "# median_1 = g[accel_cols[0]].apply(lambda x: np.median(x))\n",
    "# median_2 = g[accel_cols[1]].apply(lambda x: np.median(x))\n",
    "# median_3 = g[accel_cols[2]].apply(lambda x: np.median(x))\n",
    "# iqr_1 = g[accel_cols[0]].apply(lambda x: iqr(x))\n",
    "# iqr_2 = g[accel_cols[1]].apply(lambda x: iqr(x))\n",
    "# iqr_3 = g[accel_cols[2]].apply(lambda x: iqr(x))\n",
    "# mins = g[accel_cols].apply(lambda x: np.min(x))\n",
    "# maxs = g[accel_cols].apply(lambda x: np.max(x))\n",
    "# kurtosis_1 = g[accel_cols[0]].apply(lambda x: sp.stats.kurtosis(x))\n",
    "# kurtosis_2 = g[accel_cols[1]].apply(lambda x: sp.stats.kurtosis(x))\n",
    "# kurtosis_3 = g[accel_cols[2]].apply(lambda x: sp.stats.kurtosis(x))\n",
    "# skew_1 = g[accel_cols[0]].apply(lambda x: sp.stats.skew(x))\n",
    "# skew_2 = g[accel_cols[1]].apply(lambda x: sp.stats.skew(x))\n",
    "# skew_3 = g[accel_cols[2]].apply(lambda x: sp.stats.skew(x))\n",
    "# percentiles = []\n",
    "# for i in range(10,100,10):\n",
    "#     for e in range(1,4):\n",
    "#         percentiles.append(eval('g[accel_cols['+str(e-1)+']].apply(lambda x: sp.percentile(x,'+str(i)+'))'))\n",
    "\n",
    "# # concat columns\n",
    "# X = pd.concat([means,\n",
    "#                 sds,\n",
    "#                median_1,\n",
    "#                median_2,\n",
    "#                median_3,\n",
    "#                iqr_1,\n",
    "#                iqr_2,\n",
    "#                iqr_3,\n",
    "#                mins,\n",
    "#                maxs,\n",
    "#                kurtosis_1,\n",
    "#                kurtosis_2,\n",
    "#                kurtosis_3,\n",
    "#                skew_1,\n",
    "#                skew_2,\n",
    "#                skew_3,\n",
    "#               ]+percentiles\n",
    "#               ,axis=1)\n",
    "\n",
    "# print X.values\n",
    "\n",
    "def feature_engineering():\n",
    "    # group by user and session\n",
    "    accel_cols = ['x-accel','y-accel','z-accel']\n",
    "    g = actitracker.loc[:,accel_cols+['user','session']].groupby(['user','session'])\n",
    "    #print 'Feature engineering : {0}'.format(g[accel_cols[0]])\n",
    "\n",
    "    # IQR function\n",
    "    def iqr(x):\n",
    "        ''' calculate IQR from array\n",
    "        '''\n",
    "        q75, q25 = np.percentile(x, [75,25])\n",
    "        return q75-q25\n",
    "\n",
    "    # calculate model cols \n",
    "    means = g[accel_cols].apply(lambda x: np.mean(x))\n",
    "    sds = g[accel_cols].apply(lambda x: np.std(x))\n",
    "    median_1 = g[accel_cols[0]].apply(lambda x: np.median(x))\n",
    "    median_2 = g[accel_cols[1]].apply(lambda x: np.median(x))\n",
    "    median_3 = g[accel_cols[2]].apply(lambda x: np.median(x))\n",
    "    iqr_1 = g[accel_cols[0]].apply(lambda x: iqr(x))\n",
    "    iqr_2 = g[accel_cols[1]].apply(lambda x: iqr(x))\n",
    "    iqr_3 = g[accel_cols[2]].apply(lambda x: iqr(x))\n",
    "    mins = g[accel_cols].apply(lambda x: np.min(x))\n",
    "    maxs = g[accel_cols].apply(lambda x: np.max(x))\n",
    "    kurtosis_1 = g[accel_cols[0]].apply(lambda x: sp.stats.kurtosis(x))\n",
    "    kurtosis_2 = g[accel_cols[1]].apply(lambda x: sp.stats.kurtosis(x))\n",
    "    kurtosis_3 = g[accel_cols[2]].apply(lambda x: sp.stats.kurtosis(x))\n",
    "    skew_1 = g[accel_cols[0]].apply(lambda x: sp.stats.skew(x))\n",
    "    skew_2 = g[accel_cols[1]].apply(lambda x: sp.stats.skew(x))\n",
    "    skew_3 = g[accel_cols[2]].apply(lambda x: sp.stats.skew(x))\n",
    "    percentiles = []\n",
    "    for i in range(10,100,10):\n",
    "        for e in range(1,4):\n",
    "            percentiles.append(eval('g[accel_cols['+str(e-1)+']].apply(lambda x: sp.percentile(x,'+str(i)+'))'))\n",
    "\n",
    "    # concat columns\n",
    "    X = pd.concat([means,\n",
    "                    sds,\n",
    "                   median_1,\n",
    "                   median_2,\n",
    "                   median_3,\n",
    "                   iqr_1,\n",
    "                   iqr_2,\n",
    "                   iqr_3,\n",
    "                   mins,\n",
    "                   maxs,\n",
    "                   kurtosis_1,\n",
    "                   kurtosis_2,\n",
    "                   kurtosis_3,\n",
    "                   skew_1,\n",
    "                   skew_2,\n",
    "                   skew_3,\n",
    "                  ]+percentiles\n",
    "                  ,axis=1)\n",
    "\n",
    "    # Scale data\n",
    "    ss = StandardScaler()\n",
    "    SCALED_X = ss.fit_transform(X)\n",
    "    return X, SCALED_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, SCALED_X = feature_engineering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11018, 51) (11018, 51)\n"
     ]
    }
   ],
   "source": [
    "print X.shape, SCALED_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.6538    ,   9.8101    ,  -0.4788    ,   5.50808366,\n",
       "          3.91471365,   3.20147662,   3.065     ,  10.115     ,\n",
       "         -1.13      ,   6.68      ,   5.04      ,   2.4875    ,\n",
       "         -7.35      ,   2.37      ,  -7.04      ,  19.57      ,\n",
       "         19.23      ,  10.88      ,   0.56897302,  -0.47769409,\n",
       "          1.88286755,   0.70842968,   0.19783926,   1.07769228,\n",
       "         -2.68      ,   4.497     ,  -3.809     ,  -1.12      ,\n",
       "          6.362     ,  -2.466     ,   0.93      ,   7.545     ,\n",
       "         -1.812     ,   2.118     ,   8.826     ,  -1.452     ,\n",
       "          3.065     ,  10.115     ,  -1.13      ,   4.084     ,\n",
       "         10.776     ,  -0.708     ,   5.516     ,  11.66      ,\n",
       "         -0.38      ,   7.178     ,  12.448     ,   1.426     ,\n",
       "         10.988     ,  15.665     ,   3.437     ]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PYTHON = SCALED_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "JAVA = np.array([0.6744203688841772, 0.6843873551106622, -0.3987428844144468, 0.4029431319175183, -0.377289734834296, \n",
    " -0.26236560724347396, 0.552046672830304, 0.7361997022237357, -0.487275999906389, 0.05133813764529452,\n",
    " -0.4323964542295753, -0.4610244926063018, 0.1770880379458479, 0.7834054937667596, 0.08740075444715431, \n",
    " 1.3611399063345082, 0.5254760221123697, -0.05420441526317115, 0.2511831022116295, -0.12026082437961949, \n",
    " 0.2445062298461, 1.21718745105836, 0.27227902514453217, 0.5882338805259583, 0.4008795416540844, \n",
    " 0.6768702616612033, -0.05665883341172106, 0.4060846491472019, 0.7198273154291787, -0.02657831412724584, \n",
    " 0.575794291564951, 0.6944749499061744, -0.1112053531468206, 0.593878341741444, 0.724348150283331, -0.2922694371342172, 0.552046672830304, 0.7361997022237357, -0.487275999906389, 0.4910722520198512, 0.5219605100981608, -0.668431359283525, 0.4824070524171033, 0.3528450737871625, -0.9520635144448747, 0.49705290580762895, 0.14409012912947156, -0.6126847434922853, 0.899009379750532, 0.4106612123066219, -0.5523843015229867])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python\n",
      "[ 0.67442037  0.68438735 -0.39874288  0.39284244 -0.38469295 -0.27073944\n",
      "  0.55204667  0.7361997  -0.487276    0.04316962 -0.4613465  -0.61981107\n",
      "  0.17708804  0.78340549  0.08740075  1.36113991  0.52547602 -0.05420442\n",
      "  0.20849816 -0.13543474  0.18994672  1.19720599  0.26680613  0.56836217\n",
      "  0.40087954  0.7114132  -0.01814921  0.40608465  0.74429946 -0.01200775\n",
      "  0.57579429  0.70835576 -0.10563787  0.59743394  0.73216661 -0.28602844\n",
      "  0.55204667  0.7361997  -0.487276    0.48400511  0.52002388 -0.67110808\n",
      "  0.47265599  0.33469038 -0.95206351  0.48700076  0.12003306 -0.67065432\n",
      "  0.80566014  0.37066467 -0.62830261]\n",
      "java\n",
      "[ 0.67442037  0.68438736 -0.39874288  0.40294313 -0.37728973 -0.26236561\n",
      "  0.55204667  0.7361997  -0.487276    0.05133814 -0.43239645 -0.46102449\n",
      "  0.17708804  0.78340549  0.08740075  1.36113991  0.52547602 -0.05420442\n",
      "  0.2511831  -0.12026082  0.24450623  1.21718745  0.27227903  0.58823388\n",
      "  0.40087954  0.67687026 -0.05665883  0.40608465  0.71982732 -0.02657831\n",
      "  0.57579429  0.69447495 -0.11120535  0.59387834  0.72434815 -0.29226944\n",
      "  0.55204667  0.7361997  -0.487276    0.49107225  0.52196051 -0.66843136\n",
      "  0.48240705  0.35284507 -0.95206351  0.49705291  0.14409013 -0.61268474\n",
      "  0.89900938  0.41066121 -0.5523843 ]\n"
     ]
    }
   ],
   "source": [
    "print 'python'\n",
    "print PYTHON\n",
    "print 'java'\n",
    "print JAVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.674420367758 0.674420368884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-32.557963391107705"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print PYTHON[0], JAVA[0]\n",
    "(PYTHON[0] - JAVA[0]/ PYTHON[0])*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[  3.6538       9.8101      -0.4788       5.50808366   3.91471365\n",
    "    3.20147662   3.065       10.115       -1.13         6.68         5.04\n",
    "    2.4875      -7.35         2.37        -7.04        19.57        19.23\n",
    "   10.88         0.56897302  -0.47769409   1.88286755   0.70842968\n",
    "    0.19783926   1.07769228  -2.68         4.497       -3.809       -1.12\n",
    "    6.362       -2.466        0.93         7.545       -1.812        2.118\n",
    "    8.826       -1.452        3.065       10.115       -1.13         4.084\n",
    "   10.776       -0.708        5.516       11.66        -0.38         7.178\n",
    "   12.448        1.426       10.988       15.665        3.437     ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3.6538, 9.8101, -0.4788 [MEAN], 5.5358323637548805, 3.9344352578203394,\n",
    " 3.2176050695879974 [SD], 3.065, 10.114999999999998, -1.13,[MEDIAN] 6.720000000000001, 5.180000000000001, \n",
    " 2.9425 [IQR], -7.35, 2.37, -7.04 [MIN], 19.57, 19.23, \n",
    " 10.88 [MAX], 0.6609679359963909, -0.4399813967400168, 2.043003644404282 [KURTOSIS], 0.7192639139631538, \n",
    " 0.20086487962105667, 1.0941737575758317, [SKEWNESS] -2.68, 4.313000000000001, -3.961, [PER-10] -1.12,\n",
    " 6.248, -2.514,[PER-20] 0.93, 7.484999999999999, -1.8280000000000003 [PER-30], 2.1020000000000003, \n",
    " 8.794000000000002, -1.4679999999999995,[PER-40] 3.065, 10.114999999999998, -1.13,[PER-50] 4.115999999999999, \n",
    " 10.784, -0.7020000000000002,[PER-60] 5.563999999999998, 11.739999999999998, -0.38,[PER-70] 7.232000000000001, \n",
    " 12.562000000000001, 1.5640000000000027,[PER-80] 11.532000000000004, 15.865000000000002, 3.653000000000002][PER-90]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.66263949,   7.25317897,   0.41177204,   4.42886374,\n",
       "         4.93950666,   3.72293541,   0.65815339,   7.17444631,\n",
       "         0.01808758,   6.46860493,   7.27103294,   4.26355715,\n",
       "        -8.50827186,  -3.0321687 ,  -7.54708106,  10.47170997,\n",
       "        16.6063282 ,  11.12946631,   0.11961618,  -0.14108965,\n",
       "         1.32536016,   0.05928774,   0.05033908,   0.60629623,\n",
       "        -5.0859564 ,   0.70751293,  -3.7373639 ,  -3.34294051,\n",
       "         2.8947873 ,  -2.42644271,  -1.9010505 ,   4.48312248,\n",
       "        -1.50841476,  -0.57042206,   5.82933263,  -0.71871134,\n",
       "         0.65815339,   7.17444631,   0.01808758,   1.89242665,\n",
       "         8.6278412 ,   0.79632355,   3.18933235,  10.18516228,\n",
       "         1.73178482,   4.56183685,  11.87919567,   3.02253207,\n",
       "         6.29295251,  13.81151627,   5.22462373])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.43515743,  3.73607287,  2.23344936,  2.74720807,  2.66392459,\n",
       "        1.92605405,  4.35986073,  3.99423374,  2.35613406,  4.89684826,\n",
       "        4.83591602,  2.86548149,  6.54065556,  6.89575034,  5.80179271,\n",
       "        6.68431657,  4.99294295,  4.60232453,  2.1552077 ,  2.48536253,\n",
       "        2.93507239,  0.54221408,  0.55283656,  0.82939379,  6.00169415,\n",
       "        5.32670332,  3.94706503,  5.47408161,  4.65835712,  3.29431316,\n",
       "        4.91677417,  4.32251375,  2.87382964,  4.49994868,  4.09287629,\n",
       "        2.56369146,  4.35986073,  3.99423374,  2.35613406,  4.52799632,\n",
       "        4.13088492,  2.24155185,  4.92253925,  4.40657341,  2.21811338,\n",
       "        5.37198982,  4.73873078,  2.38055882,  5.82757823,  5.00043264,\n",
       "        2.84516364])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.std_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
